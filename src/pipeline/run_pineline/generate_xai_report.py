"""
Generate XAI Report - Narrative-style Debate Explanation
=========================================================
TrÃ­ch xuáº¥t vÃ  format láº¡i káº¿t quáº£ debate thÃ nh bÃ¡o cÃ¡o XAI dá»… Ä‘á»c,
táº­p trung vÃ o Ná»˜I DUNG há»™i thoáº¡i thay vÃ¬ sá»‘ liá»‡u ká»¹ thuáº­t.

Usage:
    python -m src.pipeline.run_pineline.generate_xai_report \
        --results-file results/vifactcheck/test/full_debate/vifactcheck_test_results.json \
        --output-dir results/vifactcheck/test/full_debate/xai_report \
        --num-examples 10
"""

import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional


# === VERDICT MAPPING ===
VERDICT_EMOJI = {
    "SUPPORTED": "âœ…",
    "REFUTED": "âŒ", 
    "NEI": "âš ï¸",
    "NOT_ENOUGH_INFO": "âš ï¸",
    "Support": "âœ…",
    "Refute": "âŒ",
}

VERDICT_VI = {
    "SUPPORTED": "ÄÃšNG",
    "REFUTED": "SAI",
    "NEI": "THIáº¾U THÃ”NG TIN",
    "NOT_ENOUGH_INFO": "THIáº¾U THÃ”NG TIN",
    "Support": "ÄÃšNG",
    "Refute": "SAI",
}

AGENT_EMOJI = {
    "x-ai/grok-4-fast": "ğŸ¯",
    "google/gemini-2.5-flash": "ğŸ’",
    "openai/gpt-4o-mini": "ğŸ¤–",
    "grok": "ğŸ¯",
    "gemini": "ğŸ’",
    "gpt": "ğŸ¤–",
}

AGENT_NAME = {
    "x-ai/grok-4-fast": "Grok",
    "google/gemini-2.5-flash": "Gemini", 
    "openai/gpt-4o-mini": "GPT",
}


def get_verdict_emoji(verdict: str) -> str:
    """Get emoji for verdict."""
    v = verdict.upper() if verdict else ""
    if "SUPPORT" in v:
        return "âœ…"
    elif "REFUT" in v:
        return "âŒ"
    else:
        return "âš ï¸"


def get_verdict_vi(verdict: str) -> str:
    """Get Vietnamese translation for verdict."""
    v = verdict.upper() if verdict else ""
    if "SUPPORT" in v:
        return "ÄÃšNG"
    elif "REFUT" in v:
        return "SAI"
    else:
        return "THIáº¾U THÃ”NG TIN"


def format_single_case(sample: Dict[str, Any], case_num: int) -> str:
    """Format a single case into narrative style."""
    lines = []
    
    # Header
    lines.append(f"### ğŸ“‹ Case {case_num}")
    lines.append("")
    
    # Claim (truncate if too long)
    statement = sample.get("statement", "N/A")
    if len(statement) > 200:
        statement = statement[:200] + "..."
    lines.append(f"**TuyÃªn bá»‘:** \"{statement}\"")
    lines.append("")
    
    # Evidence (truncate if too long)
    evidence = sample.get("evidence", "N/A")
    if len(evidence) > 300:
        evidence = evidence[:300] + "..."
    lines.append(f"**Báº±ng chá»©ng:** \"{evidence}\"")
    lines.append("")
    
    # Gold label
    gold_label = sample.get("gold_label", "N/A")
    lines.append(f"**NhÃ£n thá»±c táº¿:** {get_verdict_emoji(gold_label)} {get_verdict_vi(gold_label)}")
    lines.append("")
    
    # Model prediction
    model_verdict = sample.get("model_verdict", "N/A")
    model_correct = sample.get("model_correct", False)
    model_icon = "âœ…" if model_correct else "âŒ"
    lines.append(f"**PhoBERT dá»± Ä‘oÃ¡n:** {get_verdict_emoji(model_verdict)} {get_verdict_vi(model_verdict)} {model_icon}")
    lines.append("")
    
    # Final verdict
    final_verdict = sample.get("final_verdict", "N/A")
    final_correct = sample.get("final_correct", False)
    final_icon = "âœ…" if final_correct else "âŒ"
    lines.append(f"**Káº¿t luáº­n cuá»‘i:** {get_verdict_emoji(final_verdict)} **{get_verdict_vi(final_verdict)}** {final_icon}")
    lines.append("")
    
    # Debate transcript
    debate_result = sample.get("debate_result", {})
    if debate_result:
        lines.append("---")
        lines.append("#### ğŸ—£ï¸ Há»™i Ä‘á»“ng tranh luáº­n")
        lines.append("")
        
        # Round 1
        r1_verdicts = debate_result.get("round_1_verdicts", {})
        if r1_verdicts:
            lines.append("**VÃ²ng 1 - PhÃ¢n tÃ­ch Ä‘á»™c láº­p:**")
            lines.append("")
            for agent_id, data in r1_verdicts.items():
                agent_name = AGENT_NAME.get(agent_id, agent_id.split("/")[-1])
                emoji = AGENT_EMOJI.get(agent_id, "ğŸ”¹")
                verdict = data.get("verdict", "N/A")
                reasoning = data.get("reasoning", "N/A")
                lines.append(f"> {emoji} **{agent_name}** ({get_verdict_vi(verdict)}): \"{reasoning}\"")
                lines.append(">")
            lines.append("")
        
        # Round 2
        all_rounds = debate_result.get("all_rounds_verdicts", [])
        if len(all_rounds) >= 2:
            r2_data = all_rounds[1]  # Round 2 is index 1
            lines.append("**VÃ²ng 2 - Tranh luáº­n & Chá»‘t kÃ¨o:**")
            lines.append("")
            for agent_id, data in r2_data.items():
                agent_name = AGENT_NAME.get(agent_id, agent_id.split("/")[-1])
                emoji = AGENT_EMOJI.get(agent_id, "ğŸ”¹")
                verdict = data.get("verdict", "N/A")
                reasoning = data.get("reasoning", "N/A")
                # Check if changed
                r1_verdict = r1_verdicts.get(agent_id, {}).get("verdict", "")
                changed = r1_verdict != verdict
                change_note = " *(Ä‘á»•i Ã½)*" if changed else ""
                lines.append(f"> {emoji} **{agent_name}** ({get_verdict_vi(verdict)}{change_note}): \"{reasoning}\"")
                lines.append(">")
            lines.append("")
        
        # Judge conclusion
        judge_reasoning = debate_result.get("reasoning", "")
        if judge_reasoning:
            lines.append("**âš–ï¸ Judge káº¿t luáº­n:**")
            lines.append(f"> \"{judge_reasoning}\"")
            lines.append("")
    
    lines.append("---")
    lines.append("")
    
    return "\n".join(lines)


def categorize_samples(results: List[Dict]) -> Dict[str, List[Dict]]:
    """Categorize samples into Fixed, Broke, and Interesting cases."""
    categories = {
        "fixed": [],      # Model sai -> Debate Ä‘Ãºng
        "broke": [],      # Model Ä‘Ãºng -> Debate sai
        "consensus": [],  # Cáº£ 3 agents Ä‘á»“ng thuáº­n tá»« Ä‘áº§u
        "dramatic": [],   # CÃ³ agent Ä‘á»•i Ã½
    }
    
    for sample in results:
        model_correct = sample.get("model_correct", False)
        final_correct = sample.get("final_correct", False)
        
        # Fixed: Model wrong, Debate correct
        if not model_correct and final_correct:
            categories["fixed"].append(sample)
        # Broke: Model correct, Debate wrong
        elif model_correct and not final_correct:
            categories["broke"].append(sample)
        
        # Check for consensus/dramatic
        debate_result = sample.get("debate_result", {})
        all_rounds = debate_result.get("all_rounds_verdicts", [])
        if len(all_rounds) >= 2:
            r1 = all_rounds[0]
            r2 = all_rounds[1]
            
            # Check if any agent changed verdict
            changed = False
            for agent_id in r1:
                if agent_id in r2:
                    if r1[agent_id].get("verdict") != r2[agent_id].get("verdict"):
                        changed = True
                        break
            
            if changed:
                categories["dramatic"].append(sample)
            else:
                # Check if all same in R1
                r1_verdicts = [v.get("verdict") for v in r1.values()]
                if len(set(r1_verdicts)) == 1:
                    categories["consensus"].append(sample)
    
    return categories


def generate_report(results_file: str, output_dir: str, num_examples: int = 10):
    """Generate the XAI narrative report."""
    
    # Load results
    with open(results_file, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    results = data.get("results", [])
    total = len(results)
    
    # Create output directory
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    # Categorize samples
    categories = categorize_samples(results)
    
    # Build report
    report_lines = []
    
    # Header
    report_lines.append("# ğŸ“Š BÃO CÃO XAI - GIáº¢I THÃCH Káº¾T QUáº¢ DEBATE")
    report_lines.append("")
    report_lines.append(f"**NgÃ y táº¡o:** {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    report_lines.append(f"**Tá»•ng sá»‘ máº«u:** {total}")
    report_lines.append(f"**Äá»™ chÃ­nh xÃ¡c Model:** {data.get('model_accuracy', 0)*100:.2f}%")
    report_lines.append(f"**Äá»™ chÃ­nh xÃ¡c Debate:** {data.get('final_accuracy', 0)*100:.2f}%")
    report_lines.append("")
    report_lines.append("---")
    report_lines.append("")
    
    # Summary
    report_lines.append("## ğŸ“ˆ Tá»•ng quan")
    report_lines.append("")
    report_lines.append(f"- **Debate sá»­a Ä‘Ãºng (Fixed):** {len(categories['fixed'])} cases")
    report_lines.append(f"- **Debate lÃ m sai (Broke):** {len(categories['broke'])} cases")
    report_lines.append(f"- **Äá»“ng thuáº­n ngay (Consensus):** {len(categories['consensus'])} cases")
    report_lines.append(f"- **CÃ³ tranh luáº­n gay gáº¯t (Dramatic):** {len(categories['dramatic'])} cases")
    report_lines.append("")
    report_lines.append("---")
    report_lines.append("")
    
    # Section 1: Fixed cases
    report_lines.append("## âœ… DEBATE Sá»¬A ÄÃšNG (Model sai â†’ Debate Ä‘Ãºng)")
    report_lines.append("")
    report_lines.append("*Nhá»¯ng trÆ°á»ng há»£p PhoBERT dá»± Ä‘oÃ¡n sai, nhÆ°ng sau khi tranh luáº­n, há»‡ thá»‘ng Ä‘Ã£ sá»­a láº¡i Ä‘Ãºng.*")
    report_lines.append("")
    
    fixed_samples = categories["fixed"][:num_examples]
    for i, sample in enumerate(fixed_samples, 1):
        report_lines.append(format_single_case(sample, i))
    
    if not fixed_samples:
        report_lines.append("*KhÃ´ng cÃ³ case nÃ o trong danh má»¥c nÃ y.*")
        report_lines.append("")
    
    # Section 2: Broke cases
    report_lines.append("## âŒ DEBATE LÃ€M SAI (Model Ä‘Ãºng â†’ Debate sai)")
    report_lines.append("")
    report_lines.append("*Nhá»¯ng trÆ°á»ng há»£p PhoBERT dá»± Ä‘oÃ¡n Ä‘Ãºng, nhÆ°ng sau tranh luáº­n láº¡i bá»‹ Ä‘á»•i thÃ nh sai (over-reasoning).*")
    report_lines.append("")
    
    broke_samples = categories["broke"][:num_examples]
    for i, sample in enumerate(broke_samples, 1):
        report_lines.append(format_single_case(sample, i))
    
    if not broke_samples:
        report_lines.append("*KhÃ´ng cÃ³ case nÃ o trong danh má»¥c nÃ y.*")
        report_lines.append("")
    
    # Section 3: Dramatic cases
    report_lines.append("## ğŸ”¥ TRANH LUáº¬N GAY Gáº®T (CÃ³ agent Ä‘á»•i Ã½)")
    report_lines.append("")
    report_lines.append("*Nhá»¯ng trÆ°á»ng há»£p cÃ³ Ã­t nháº¥t 1 agent thay Ä‘á»•i quan Ä‘iá»ƒm sau vÃ²ng tranh luáº­n.*")
    report_lines.append("")
    
    dramatic_samples = categories["dramatic"][:num_examples]
    for i, sample in enumerate(dramatic_samples, 1):
        report_lines.append(format_single_case(sample, i))
    
    if not dramatic_samples:
        report_lines.append("*KhÃ´ng cÃ³ case nÃ o trong danh má»¥c nÃ y.*")
        report_lines.append("")
    
    # Write report
    report_content = "\n".join(report_lines)
    report_file = output_path / "xai_narrative_report.md"
    with open(report_file, "w", encoding="utf-8") as f:
        f.write(report_content)
    
    print(f"âœ… ÄÃ£ táº¡o bÃ¡o cÃ¡o XAI: {report_file}")
    print(f"   - Fixed cases: {len(categories['fixed'])}")
    print(f"   - Broke cases: {len(categories['broke'])}")
    print(f"   - Dramatic cases: {len(categories['dramatic'])}")
    
    return str(report_file)


def main():
    parser = argparse.ArgumentParser(description="Generate XAI Narrative Report")
    parser.add_argument(
        "--results-file",
        type=str,
        default="results/vifactcheck/test/full_debate/vifactcheck_test_results.json",
        help="Path to results JSON file"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="results/vifactcheck/test/full_debate/xai_report",
        help="Output directory for report"
    )
    parser.add_argument(
        "--num-examples",
        type=int,
        default=10,
        help="Number of examples per category"
    )
    
    args = parser.parse_args()
    generate_report(args.results_file, args.output_dir, args.num_examples)


if __name__ == "__main__":
    main()
